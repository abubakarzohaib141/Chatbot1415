{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORupD7yF59y1bNBH9k2IVF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abubakarzohaib141/Chatbot1415/blob/main/Outfit_Clothes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnGZhcV9NC0f",
        "outputId": "b4c86691-61a1-49a4-cf49-911a2f4025d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: GOOGLE_API_KEY=AIzaSyC86dtGJF3P1yRRhvlapRzLwJHfLWaavXY\n",
            "env: LANGCHAIN_API_KEY=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\n"
          ]
        }
      ],
      "source": [
        "%pip install --quiet -U langchain_core langgraph langchain_google_genai\n",
        "import os\n",
        "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langgraph.graph import MessagesState, StateGraph, START, END\n",
        "from langgraph.graph.state import CompiledStateGraph\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "\n",
        "%env GOOGLE_API_KEY = {userdata.get('GEMINI_API_KEY')}\n",
        "%env LANGCHAIN_API_KEY = {userdata.get('LANGCHAIN_API_KEY')}\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"clothes-shop-chatbot\"\n",
        "\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extend MessagesState for custom chatbot state\n",
        "class ShopState(MessagesState):\n",
        "    summary: str\n",
        "    customer_preferences: dict = {}"
      ],
      "metadata": {
        "id": "GthRjZDJQ6T_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the main logic for responding to user queries\n",
        "def call_model(state: ShopState) -> ShopState:\n",
        "    # Retrieve existing summary and preferences\n",
        "    summary = state.get(\"summary\", \"\")\n",
        "    customer_prefs = state.get(\"customer_preferences\", {})\n",
        "\n",
        "    # Build the system message with summary and preferences\n",
        "    system_message = (\n",
        "        f\"Summary of conversation: {summary}\\nCustomer Preferences: {customer_prefs}\"\n",
        "        if summary else \"\"\n",
        "    )\n",
        "    messages = [SystemMessage(content=system_message)] + state[\"messages\"] if summary else state[\"messages\"]\n",
        "\n",
        "    # Get the response from the model\n",
        "    response = model.invoke(messages)\n",
        "    return {\"messages\": response, \"customer_preferences\": customer_prefs}\n"
      ],
      "metadata": {
        "id": "enx9KAGoRH_5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize the conversation and manage memory\n",
        "def summarize_conversation(state: ShopState):\n",
        "    summary = state.get(\"summary\", \"\")\n",
        "\n",
        "    # Create summarization prompt\n",
        "    summary_message = (\n",
        "        f\"Extend the summary considering new messages about shopping preferences:\\n\\n{summary}\"\n",
        "        if summary else \"Summarize the conversation related to product queries and preferences.\"\n",
        "    )\n",
        "\n",
        "    # Add prompt to the message history\n",
        "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
        "    response = model.invoke(messages)\n",
        "\n",
        "    # Retain only the last 2 messages and update the summary\n",
        "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
        "    return {\"summary\": response.content, \"messages\": delete_messages}\n"
      ],
      "metadata": {
        "id": "jpy-HlLeRZWQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to decide the next step in the workflow\n",
        "def should_continue(state: ShopState):\n",
        "    \"\"\"\n",
        "    Decide whether to continue the conversation or summarize.\n",
        "    \"\"\"\n",
        "    messages = state.get(\"messages\", [])\n",
        "\n",
        "    # If more than 6 messages, trigger summarization\n",
        "    if len(messages) > 6:\n",
        "        return \"summarize_conversation\"\n",
        "\n",
        "    # Otherwise, end the conversation\n",
        "    return END\n"
      ],
      "metadata": {
        "id": "_CTLgMiWR4_V"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the workflow\n",
        "workflow = StateGraph(ShopState)\n",
        "\n",
        "# Add nodes for conversation and summarization\n",
        "workflow.add_node(\"conversation\", call_model)\n",
        "workflow.add_node(\"summarize_conversation\", summarize_conversation)\n",
        "\n",
        "# Define edges for conversation flow\n",
        "workflow.add_edge(START, \"conversation\")\n",
        "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
        "workflow.add_edge(\"summarize_conversation\", END)\n",
        "\n",
        "# Compile the graph with memory saver\n",
        "memory = MemorySaver()\n",
        "graph = workflow.compile(checkpointer=memory)\n"
      ],
      "metadata": {
        "id": "zJO6GC-WRfwd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a unique thread for each user session\n",
        "config = {\"configurable\": {\"thread_id\": \"customer-1\"}}\n",
        "\n",
        "# Start the conversation in a specific thread\n",
        "input_message = HumanMessage(content=\"Hi, I'm looking for a blue shirt.\")\n",
        "output = graph.invoke({\"messages\": [input_message]}, config)\n"
      ],
      "metadata": {
        "id": "-ZS2TtinR-8n"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First conversation in thread \"customer-1\"\n",
        "input_message = HumanMessage(content=\"Hi, I'm looking for a blue shirt.\")\n",
        "output = graph.invoke({\"messages\": [input_message]}, config)\n",
        "for message in output[\"messages\"][-1:]:\n",
        "    print(message.pretty_print())\n",
        "\n",
        "# Continue the conversation in the same thread\n",
        "input_message = HumanMessage(content=\"Do you have it in medium size?\")\n",
        "output = graph.invoke({\"messages\": [input_message]}, config)\n",
        "for message in output[\"messages\"][-1:]:\n",
        "    print(message.pretty_print())\n",
        "\n",
        "# Retrieve the state for debugging\n",
        "state = graph.get_state(config)\n",
        "print(\"Summary:\", state.values.get(\"summary\", \"No summary available\"))\n",
        "print(\"Messages:\", state.values.get(\"messages\", []))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzcD-UZATGr9",
        "outputId": "569a835a-acf4-4f60-8368-c225efb36bba"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I understand you're looking for a blue shirt.  To help me narrow down your search, could you please tell me:\n",
            "\n",
            "* **What specific shade of blue are you interested in?** (e.g., navy, sky blue, royal blue, turquoise, powder blue)  A description or even a picture would be helpful!\n",
            "* **What style of shirt are you looking for?** (e.g., t-shirt, polo shirt, button-down shirt, henley shirt, flannel shirt)\n",
            "* **What is your size?** (Please specify men's or women's sizing and the specific size, e.g., Men's Large, Women's Small)\n",
            "* **What material would you prefer?** (e.g., cotton, silk, linen, polyester blend)\n",
            "* **For what occasion will you be wearing the shirt?** (e.g., casual, formal, work, a specific event)\n",
            "\n",
            "The more details you can provide, the better I can assist you in finding the perfect blue shirt.\n",
            "None\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "I need more information to determine if we have a blue shirt in a medium size.  Please tell me:\n",
            "\n",
            "* **What shade of blue?**\n",
            "* **What style of shirt?** (e.g., t-shirt, polo, button-down, etc.)\n",
            "* **What material?** (e.g., cotton, linen, etc.)\n",
            "\n",
            "Once I have this information, I can better assist you.\n",
            "None\n",
            "Summary: The conversation demonstrates the challenges of fulfilling a vague product request.  The user's simple query, \"I'm looking for a blue shirt,\" is insufficient for an AI assistant to provide relevant results.  Repeatedly, the AI prompts the user for crucial details, including the specific shade of blue (e.g., navy, sky blue), the desired shirt style (t-shirt, polo, button-down, etc.), the preferred material (cotton, linen, etc.), the required size (including gender specification â€“ men's or women's), and the intended use or occasion for the shirt.  The user's lack of further specification underscores the importance of providing comprehensive information when making online product inquiries.  The AI's persistent requests highlight the limitations of AI in fulfilling ambiguous requests and the necessity of clear communication between the user and the AI system for a successful shopping experience.  Even a seemingly simple request like \"a blue shirt\" requires significant clarification to become actionable.  The final, partial response from the user (\"Do you have it in medium size?\") further illustrates the piecemeal nature of the information provided and the ongoing difficulty in fulfilling the request without complete details.\n",
            "\n",
            "Messages: [HumanMessage(content='Do you have it in medium size?', additional_kwargs={}, response_metadata={}, id='d342e6c6-0f77-4118-bd1c-2d22ceb4d23e'), AIMessage(content='I need more information to determine if we have a blue shirt in a medium size.  Please tell me:\\n\\n* **What shade of blue?**\\n* **What style of shirt?** (e.g., t-shirt, polo, button-down, etc.)\\n* **What material?** (e.g., cotton, linen, etc.)\\n\\nOnce I have this information, I can better assist you.\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-f287286d-351a-47bb-8e1e-01b22dcdf601-0', usage_metadata={'input_tokens': 753, 'output_tokens': 89, 'total_tokens': 842, 'input_token_details': {'cache_read': 0}})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to run a chatbot session with tool-calling and improved summaries\n",
        "def run_chatbot():\n",
        "    # Configuration for a unique thread\n",
        "    config = {\"configurable\": {\"thread_id\": \"customer-1\"}}\n",
        "\n",
        "    print(\"Welcome to the Clothes Shop Chatbot! Type 'exit' to end the conversation.\")\n",
        "\n",
        "    while True:\n",
        "        # Take user input\n",
        "        user_input = input(\"You: \")\n",
        "\n",
        "        # Break the loop if the user wants to exit\n",
        "        if user_input.lower() == \"exit\":\n",
        "            print(\"Goodbye! Thank you for chatting.\")\n",
        "            break\n",
        "\n",
        "        # Create a new message from user input\n",
        "        input_message = HumanMessage(content=user_input)\n",
        "\n",
        "        # Invoke the chatbot graph with the new message\n",
        "        output = graph.invoke({\"messages\": [input_message]}, config)\n",
        "\n",
        "        # Handle Tool-Calling (e.g., check inventory, get price)\n",
        "        bot_response, tool_result = handle_tool_calling(output[\"messages\"][-1], user_input)\n",
        "\n",
        "        # Display the chatbot's response\n",
        "        print(f\"Chatbot: {bot_response}\")\n",
        "\n",
        "        # Optional: Retrieve and show the updated state without unnecessary summaries\n",
        "        state = graph.get_state(config)\n",
        "        clean_summary = filter_summary(state.values.get(\"summary\", \"\"))\n",
        "        if clean_summary:\n",
        "            print(\"\\nCurrent Conversation Summary:\")\n",
        "            print(clean_summary)\n",
        "\n",
        "\n",
        "# Function to clean the conversation summary (removing unwanted AI-related details)\n",
        "def filter_summary(summary):\n",
        "    if \"challenges\" in summary.lower():\n",
        "        return None  # Skip summaries with unwanted content\n",
        "    return summary\n",
        "\n",
        "\n",
        "# Function to handle tool-calling logic\n",
        "def handle_tool_calling(bot_response, user_input):\n",
        "    tool_result = None\n",
        "\n",
        "    # Example Tool-Calling Logic (Add your custom tool calls here)\n",
        "    if \"blue shirt\" in user_input.lower():\n",
        "        # Simulated tool response\n",
        "        tool_result = \"Blue shirts available in Medium and Large sizes. Price: $25.\"\n",
        "        bot_response += f\"\\nTool Result: {tool_result}\"\n",
        "\n",
        "    if \"price\" in user_input.lower():\n",
        "        # Simulated tool response for price query\n",
        "        tool_result = \"The price for blue shirts is $25.\"\n",
        "        bot_response += f\"\\nTool Result: {tool_result}\"\n",
        "\n",
        "    # Add more tool-calling logic as needed for inventory, order placement, etc.\n",
        "    return bot_response, tool_result\n",
        "\n",
        "\n",
        "# Run the chatbot\n",
        "run_chatbot()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YltVP_PJTOSF",
        "outputId": "075b84f9-ac9a-4ff4-815c-14eb4f71e7b9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the Clothes Shop Chatbot! Type 'exit' to end the conversation.\n",
            "You: Hello\n",
            "Chatbot: content='Hello! How can I help you today?\\n' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run-57676194-276b-4581-8e0d-7458fd1f938b-0' usage_metadata={'input_tokens': 422, 'output_tokens': 10, 'total_tokens': 432, 'input_token_details': {'cache_read': 0}}\n",
            "You: I want a blue navy shirt\n",
            "Chatbot: content='Okay, a navy blue shirt.  To help me find the perfect shirt for you, could you tell me:\\n\\n* **What type of shirt?** (e.g., t-shirt, polo shirt, dress shirt, etc.)\\n* **What material is it made of?** (e.g., cotton, linen, polyester, etc.)\\n* **Is it for men or women?**\\n* **What size are you looking for?**\\n\\nThe more information you can give me, the better I can assist you.\\n' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run-624548ed-9c8d-4e2f-b4e7-6ab45c3ad9e0-0' usage_metadata={'input_tokens': 440, 'output_tokens': 112, 'total_tokens': 552, 'input_token_details': {'cache_read': 0}}\n",
            "You: t-shirt cotton male small\n",
            "Chatbot: content=\"Okay, a small men's cotton t-shirt in navy blue.  Is there a specific brand you prefer?\\n\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run-bcb78d07-9f2e-4602-a701-951997098c54-0' usage_metadata={'input_tokens': 560, 'output_tokens': 25, 'total_tokens': 585, 'input_token_details': {'cache_read': 0}}\n",
            "You: adidias\n",
            "Chatbot: content=\"Okay, a small men's cotton t-shirt, navy blue, Adidas.  Do you have a price range in mind?\\n\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run-ae20ede7-cd33-45d2-ac34-736d3c639ad4-0' usage_metadata={'input_tokens': 336, 'output_tokens': 28, 'total_tokens': 364, 'input_token_details': {'cache_read': 0}}\n",
            "You: no\n",
            "Chatbot: content=\"Okay.  I'll try to find you a small men's navy blue Adidas cotton t-shirt.  However, to get the best results, specifying a price range would help narrow down the search.  Do you have a maximum price you'd like to pay?\\n\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run-cf3b2a9a-7629-4119-bd6a-ac6320ea7182-0' usage_metadata={'input_tokens': 367, 'output_tokens': 58, 'total_tokens': 425, 'input_token_details': {'cache_read': 0}}\n",
            "You: 25$\n",
            "Chatbot: content=\"Okay, a small men's navy blue Adidas cotton t-shirt, with a maximum price of $25.  I will now try to locate this for you.  (Please note that the availability and exact price may vary depending on the retailer and current stock.)\\n\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run-ff59cb32-badf-4b84-b0b2-36dc3b4b1cf2-0' usage_metadata={'input_tokens': 430, 'output_tokens': 56, 'total_tokens': 486, 'input_token_details': {'cache_read': 0}}\n",
            "You: exit\n",
            "Goodbye! Thank you for chatting.\n"
          ]
        }
      ]
    }
  ]
}